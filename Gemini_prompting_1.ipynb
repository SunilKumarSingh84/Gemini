{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunilKumarSingh84/Gemini/blob/main/Gemini_prompting_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompting Tutorial"
      ],
      "metadata": {
        "id": "PG4xg-SSZyJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing necessary libraries"
      ],
      "metadata": {
        "id": "8wvlR9V08W7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai\n"
      ],
      "metadata": {
        "id": "AuTdu8LNZ6_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing, Authenticating and Configuring Gemini Client"
      ],
      "metadata": {
        "id": "Kqp6Rv2U8dSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "H-vu0-2fZ9qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing the Model"
      ],
      "metadata": {
        "id": "mim8QHl68xXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"gemini-2.0-flash-thinking-exp-01-21\")"
      ],
      "metadata": {
        "id": "-aEVYhnTc5wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompting"
      ],
      "metadata": {
        "id": "lvPrl6nV828L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of basic prompting"
      ],
      "metadata": {
        "id": "pfMx-IGsq2Pc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRX-R96KtnIa"
      },
      "outputs": [],
      "source": [
        "# --- Basic Prompting ---\n",
        "prompt_basic = \"Write a short poem.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using GenAI Model Client to get the response"
      ],
      "metadata": {
        "id": "5SwTzRwr8_JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_basic = model.generate_content(prompt_basic)\n"
      ],
      "metadata": {
        "id": "WUsNZwTw17xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To print the response"
      ],
      "metadata": {
        "id": "nZA2mva-9NaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_basic.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s1t5c3K-2V4t",
        "outputId": "0a608101-b557-4531-add9-04b160743edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Soft rain on thirsty ground,\\nA gentle, hushed and quiet sound.\\nThe world drinks deep, refreshed and new,\\nBeneath the sky of softest blue.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_basic.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWVvSZyJfSBY",
        "outputId": "bce89d5a-76ed-4a57-d8be-0cf0768133b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soft rain on thirsty ground,\n",
            "A gentle, hushed and quiet sound.\n",
            "The world drinks deep, refreshed and new,\n",
            "Beneath the sky of softest blue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Role Prompting\n"
      ],
      "metadata": {
        "id": "1h1lTja36KrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " we can start to create a \"messages\" dictionary which we pass to AI which provides it instructions."
      ],
      "metadata": {
        "id": "yY2lr2ZbtkEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a helpful and elaboratory assistant who is expert in geography\"\n",
        "user_prompt = \"What is the capital of Italy?\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"parts\": system_prompt},\n",
        "    {\"role\": \"user\", \"parts\": user_prompt}\n",
        "]\n",
        "\n",
        "response = model.generate_content(messages)\n",
        "print(response.text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "A5CTSb42tQP3",
        "outputId": "edd8cd69-71b0-46d4-c22a-4ff2872cc401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of Italy is **Rome**.\n",
            "\n",
            "Rome is not only the capital of Italy but also its largest city and one of the most historically and culturally significant cities in the world.  It's often referred to as the \"Eternal City\" due to its long history and enduring influence.\n",
            "\n",
            "Here are some fascinating facts about Rome:\n",
            "\n",
            "*   **Ancient History:** Rome was the capital of the Roman Empire, which dominated much of Europe, North Africa, and the Middle East for centuries.  Its history stretches back over 2,800 years! You can still see incredible remnants of this ancient empire throughout the city, such as the Colosseum, the Roman Forum, and the Pantheon.\n",
            "*   **Vatican City:**  Within Rome, you'll find Vatican City, the smallest country in the world and the center of the Roman Catholic Church. St. Peter's Basilica and the Vatican Museums (home to the Sistine Chapel) are major attractions within Vatican City.\n",
            "*   **Seven Hills:** Rome is traditionally said to be built on seven hills: the Aventine, Caelian, Capitoline, Esquiline, Palatine, Quirinal, and Viminal Hills. These hills played a significant role in the city's early development and defense.\n",
            "*   **Trevi Fountain:** This iconic Baroque fountain is famous for the tradition of throwing coins into it to ensure a return trip to Rome.\n",
            "*   **Food and Culture:** Rome is renowned for its delicious cuisine, including pasta dishes like Cacio e Pepe and Carbonara, pizza, gelato, and espresso.  The city also boasts a vibrant arts and culture scene, with numerous museums, galleries, theaters, and opera houses.\n",
            "*   **Modern Capital:**  While Rome's history is ancient, it officially became the capital of the Kingdom of Italy in 1871, after Italy unified. Before that, Florence and Turin had briefly served as capitals.\n",
            "\n",
            "So, in summary, the capital of Italy is **Rome**, a city brimming with history, art, culture, and delicious food, making it a truly remarkable place to visit and a significant capital city on the world stage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example with more detailed parts for each message."
      ],
      "metadata": {
        "id": "12rsPFYGt7Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detailed_messages = [\n",
        "    {\"role\": \"user\", \"parts\": [\"You are a helpful and concise assistant that specializes in geography.\"]},\n",
        "    {\"role\": \"user\", \"parts\": [\"What is the capital of Italy?\", \"Please respond in two sentence.\"]}\n",
        "]\n",
        "\n",
        "try:\n",
        "    detailed_response = model.generate_content(detailed_messages)\n",
        "    print(detailed_response.text)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred in detailed example: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Z_-8pou1tdgn",
        "outputId": "7c24fde4-46ac-470a-a454-ce05f9f131f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rome is the capital of Italy.  This historic city is located in the Lazio region of central Italy and has served as the capital for centuries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hYJ4USW0tfbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can experiment with adding an assistant message also and further user messages to act as a conversation"
      ],
      "metadata": {
        "id": "zNw_my1qrKIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are an Interview AI Assistant dedicated to give interviews. Pretend to give me an interview for a role in data science\""
      ],
      "metadata": {
        "id": "X58Iuk3prK0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant_message = \"Hello, take a seat\""
      ],
      "metadata": {
        "id": "YT1_MItyrQPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = \"Hi there\""
      ],
      "metadata": {
        "id": "IOpY_pLbrTLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"parts\": system_prompt},\n",
        "    {\"role\": \"model\", \"parts\": assistant_message},\n",
        "    {\"role\": \"user\", \"parts\": user_message}\n",
        "]"
      ],
      "metadata": {
        "id": "6u3ok1GsrVzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    detailed_response = model.generate_content(messages)\n",
        "    print(detailed_response.text)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred in detailed example: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "00xL46J4rmq2",
        "outputId": "050efb68-0999-4930-f1e8-f5be107afe4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great!  Thanks for coming in today. I'm excited to chat with you about the Data Scientist role at [Company Name].  My name is [My AI Assistant Name], and I'll be conducting this first round interview.\n",
            "\n",
            "To start, could you briefly introduce yourself and tell me a bit about what interests you in data science and this particular role at [Company Name]?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try yourself:- Now you can continue the conversation with the model"
      ],
      "metadata": {
        "id": "3Q1vmgQu_lAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To keep the conversation going, you have to append the response from model to the message"
      ],
      "metadata": {
        "id": "w2xLl11L_m_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRY4F-jf-8cC",
        "outputId": "f8506c53-4397-4f1a-8490-eca6f44af3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'parts': 'You are an Interview AI Assistant dedicated to give interviews. Pretend to give me an interview for a role in data science'},\n",
              " {'role': 'model', 'parts': 'Hello, take a seat'},\n",
              " {'role': 'user', 'parts': 'Hi there'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\": \"model\", \"parts\": detailed_response.text})"
      ],
      "metadata": {
        "id": "SyGDCAae_iUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwhrcbeDAcb2",
        "outputId": "e62a6635-951d-480f-c221-307b916a34c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'parts': 'You are an Interview AI Assistant dedicated to give interviews. Pretend to give me an interview for a role in data science'},\n",
              " {'role': 'model', 'parts': 'Hello, take a seat'},\n",
              " {'role': 'user', 'parts': 'Hi there'},\n",
              " {'role': 'model',\n",
              "  'parts': \"Great!  Thanks for coming in today. I'm excited to chat with you about the Data Scientist role at [Company Name].  My name is [My AI Assistant Name], and I'll be conducting this first round interview.\\n\\nTo start, could you briefly introduce yourself and tell me a bit about what interests you in data science and this particular role at [Company Name]?\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_message= \" .. \""
      ],
      "metadata": {
        "id": "PicLXB8SAePk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the user message to message variable\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "igVZmQPLAkCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(messages)\n",
        "\n"
      ],
      "metadata": {
        "id": "YM2AgGyGAk7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.text\n",
        "\n"
      ],
      "metadata": {
        "id": "TR5vouPeAts0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making a simple chatbot with 'while' loop\n"
      ],
      "metadata": {
        "id": "J3pihAz68k7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m50rPw-nnNPT",
        "outputId": "cf93a5c1-c28c-42a6-c477-94202534cc68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'parts': 'You are an Interview AI Assistant dedicated to give interviews. Pretend to give me an interview for a role in data science'},\n",
              " {'role': 'model', 'parts': 'Hello, take a seat'},\n",
              " {'role': 'user', 'parts': 'Hi there'},\n",
              " {'role': 'model',\n",
              "  'parts': \"Great!  Thanks for coming in today. I'm excited to chat with you about the Data Scientist role at [Company Name].  My name is [My AI Assistant Name], and I'll be conducting this first round interview.\\n\\nTo start, could you briefly introduce yourself and tell me a bit about what interests you in data science and this particular role at [Company Name]?\"},\n",
              " {'role': 'user', 'parts': 'my name is vishal'},\n",
              " {'role': 'user', 'parts': 'im intrested in gen ai models from azure openai'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\": \"model\", \"parts\": response.text})"
      ],
      "metadata": {
        "id": "BRmwM-piAwhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = input(\"You: \")\n",
        "messages.append({\"role\": \"user\", \"parts\": user_message})"
      ],
      "metadata": {
        "id": "wBeXrDtb9g-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749cba7d-4bcc-4484-a7af-8e4b571c0697"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: im from data science background\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        # Generate response\n",
        "        detailed_response = model.generate_content(messages)\n",
        "        print(\"Chatbot:\", detailed_response.text)\n",
        "\n",
        "        # Get the next user input\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            break\n",
        "        messages.append({\"role\": \"model\", \"parts\": detailed_response.text})\n",
        "        messages.append({\"role\": \"user\", \"parts\": user_input})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        break"
      ],
      "metadata": {
        "id": "my7FUV7o8zo3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "5851973c-299d-441f-a6da-5d0e2919f23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Great to meet you, Vishal. Thanks for taking the time to interview with us today for the Data Science role. My name is Interview AI Assistant, and I'll be leading this interview.\n",
            "\n",
            "To start, could you please walk me through your background and experience in data science? I'm particularly interested in understanding the types of projects you've worked on, the tools and technologies you're comfortable with, and what aspects of data science you find most engaging.\n",
            "You: hi \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-thinking-exp-01-21:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 787.17ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-01-21:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qpU75vSI9QXo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}